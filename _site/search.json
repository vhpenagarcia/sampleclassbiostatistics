[
  {
    "objectID": "sampleclassbiostatistics.html",
    "href": "sampleclassbiostatistics.html",
    "title": "Statistical Inference: Mean estimation",
    "section": "",
    "text": "Welcome to the section “Statistical Inference: Mean estimation”. For this practice we are going to need to load the package tidyverse. In case you don’t have the package installed in your console, you can execute the following line of code:\n# Run this code only if you don't have the package installed\ninstall.packages(\"tidyverse\")\nIf you have it, the you only need to load it by execute the following code:\nlibrary(tidyverse)\nTo begin, let’s remember what a mean is\n\\mu=\\frac{1}{n}\\displaystyle\\sum_{i=1}^n x_i"
  },
  {
    "objectID": "sampleclassbiostatistics.html#the-law-of-large-numbers",
    "href": "sampleclassbiostatistics.html#the-law-of-large-numbers",
    "title": "Statistical Inference: Mean estimation",
    "section": "The law of large numbers",
    "text": "The law of large numbers\nFollowing with the example of the fictitious population:\n\nset.seed(10)\npoblacion &lt;- rnorm(5000, 1.09, 0.4)\n\nNow let’s take samples with varying n and plotting the distribution. Let’s start with n=10.\n\nknitr::opts_chunk$set(warning = FALSE)\nsamples1 &lt;- replicate(B, {\n  sample &lt;- sample(poblacion, 10)\n  mean(sample)\n})\ndata.frame(samples1) %&gt;% \n  ggplot(aes(samples1)) +\n  geom_histogram(col = \"black\", fill = \"gray70\") +\n  geom_vline(xintercept = 1.09, linetype = \"dashed\", col = \"blue\") +\n  xlim(0.6, 1.5)\n\n\n\n\n\n\n\n\nNow let’s try with n=25:\n\nknitr::opts_chunk$set(warning = FALSE)\nsamples2 &lt;- replicate(B, {\n  sample &lt;- sample(poblacion, 25)\n  mean(sample)\n})\ndata.frame(samples2) %&gt;% \n  ggplot(aes(samples2)) +\n  geom_histogram(col = \"black\", fill = \"gray70\") +\n  geom_vline(xintercept = 1.09, linetype = \"dashed\", col = \"blue\") +\n  xlim(0.6, 1.5)\n\n\n\n\n\n\n\n\nand let’s finish with n=100:\n\nknitr::opts_chunk$set(warning = FALSE)\nsamples3 &lt;- replicate(B, {\n  sample &lt;- sample(poblacion, 100)\n  mean(sample)\n})\ndata.frame(samples3) %&gt;% \n  ggplot(aes(samples3)) +\n  geom_histogram(col = \"black\", fill = \"gray70\") +\n  geom_vline(xintercept = 1.09, linetype = \"dashed\", col = \"blue\") +\n  xlim(0.6, 1.5)\n\n\n\n\n\n\n\n\nAs the sample size increases the variance decreases. From there we can estimate the error made in the estimation from a single sample of size n.\n\nSE(\\overline{x})=\\sqrt{var(\\overline{x})}=\\frac{\\sigma}{\\sqrt{n}}\n\nThis value is known as standard error and allows us to quantify the degree of uncertainty in the estimation of a mean from a sample of size n. However, the study variable’s population variance \\sigma^2 is unknown. So, it can be estimated from data by using the sample variance:\n\nS^2=\\frac{1}{n-1}\\displaystyle\\sum_{i=1}^n (x_i-\\overline{x})^2\n\nThus, the standard error of the sample is estimated as:\n\nSE(\\overline{x})=\\frac{S}{\\sqrt{n}}\n\n\nExample\nEstimate the mean and the standard error of the sample:\n\nset.seed(6)\nsample1 &lt;- sample(population, 10)\n\nTo estimate the mean, we can just use the mean function:\n\nsample_mean &lt;- mean(sample1)\nsample_mean\n\n[1] 1.158018\n\n\nWe can estimate the variance using the equation or using the function var directly:\n\nvariance &lt;- sum((sample1 - sample_mean)^2)/(10-1)\nvar(sample1)\n\n[1] 0.1104093\n\n\nNow, let’s estimate the standard deviation of the sample and the consequent standard error:\n\nS &lt;- sqrt(variance)\nSE &lt;- S/sqrt(10)\nSE\n\n[1] 0.1050758\n\n\nNow, we have it!!\nBut wait!! We know that the mean is an important parameter for normal distributions along with standard deviation, which seems to fit pretty well with the standard error. But what if the study variable is not normally distributed?\nLet’s talk about the Central Limit Theorem!"
  },
  {
    "objectID": "sampleclassbiostatistics.html#central-limit-theorem",
    "href": "sampleclassbiostatistics.html#central-limit-theorem",
    "title": "Statistical Inference: Mean estimation",
    "section": "Central Limit Theorem",
    "text": "Central Limit Theorem\nAs population samples are drawn, the distribution of the means has the tendency to follow a normal distribution. That’s very intuitive if the trait is normally distributed in the population. However, the same behavior prevails when the population has other distribution.\nLet’s take an example of a gamma-distributed population variable:\n\npopulation &lt;- rgamma(5000, shape = 2, scale = 2)\npopulation_df &lt;- data.frame(population)\npopulation_df %&gt;% ggplot(aes(population)) +\n  geom_histogram(col = \"black\", fill = \"gray70\")\n\n\n\n\n\n\n\nmean(population)\n\n[1] 3.961046\n\n\nAs you can see, the mean of this trait has a value close to 4.0. But because the population has a gamma distribution it seems to be not very important, right?\nNow, let’s take sample of different sizes. Let’s start with n=10:\n\nknitr::opts_chunk$set(warning = FALSE)\nsamples1 &lt;- replicate(B, {\n  sample &lt;- sample(population, 10)\n  mean(sample)\n})\ndata.frame(samples1) %&gt;% \n  ggplot(aes(samples1)) +\n  geom_histogram(col = \"black\", fill = \"gray70\") +\n  geom_vline(xintercept = 4.0, linetype = \"dashed\", col = \"blue\") +\n  xlim(1.8, 8.6)\n\n\n\n\n\n\n\n\nDistribution seems slightly different from the original, right? So, let’s increase the sample size to n=25:\n\nknitr::opts_chunk$set(warning = FALSE)\nsamples2 &lt;- replicate(B, {\n  sample &lt;- sample(population, 25)\n  mean(sample)\n})\ndata.frame(samples2) %&gt;% \n  ggplot(aes(samples2)) +\n  geom_histogram(col = \"black\", fill = \"gray70\") +\n  geom_vline(xintercept = 4.0, linetype = \"dashed\", col = \"blue\") +\n  xlim(1.8, 8.6)\n\n\n\n\n\n\n\n\nand now, we’re going to try samples of size n=100:\n\nknitr::opts_chunk$set(warning = FALSE)\nsamples3 &lt;- replicate(B, {\n  sample &lt;- sample(population, 100)\n  mean(sample)\n})\ndata.frame(samples3) %&gt;% \n  ggplot(aes(samples3)) +\n  geom_histogram(col = \"black\", fill = \"gray70\") +\n  geom_vline(xintercept = 4.0, linetype = \"dashed\", col = \"blue\") +\n  xlim(1.8, 8.6)\n\n\n\n\n\n\n\n\nFrom these examples it follows that regardless of the distribution of the random variable in the population, the distribution of the sample means tends to follow a normal distribution, specially when sample size increases, which is known as Central Limit Theorem.\nFormally, distribution of the means of simple random samples of size n approximates as sample size increases to a normal distribution with mean \\mu and variance \\sigma^2 / n:\n\n\\overline{x}\\sim\\mathcal{N}(\\mu,\\frac{\\sigma}{\\sqrt{n}})\n\nI hope you enjoyed it!"
  }
]